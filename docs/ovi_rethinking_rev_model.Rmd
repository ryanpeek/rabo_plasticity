---
title: "Oviposition Logistic"
author: "Ryan Peek"
date: "Updated: `r format(Sys.Date())`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("../"))
```

# What Permits Plasticity in Breeding Timing in River Frogs?

How might varying environmental conditions provide cues for breeding timing from year to year? For frogs that have an amazing plasticity in breeding oviposition timing (inital deposition of eggs) such as *Rana boylii*, there must be certain thresholds that exist (a cutoff which makes oviposition not possible, physiologically). However, beyond a given threshold, there also may be certain cues which act as important environmental markers in dynamic environments such as rivers. By utilizing both, it is likely that the odds of reproductive success improve, and over time this results in evolutionary success. For example, frogs that breed to soon are more likely to have eggs scoured out by late spring storms or have longer developmental/hatching times because water temperatures are lower. Frogs breeding later in the season may trade off greater egg deposition and hatching success with later metamorphosis and lower overwinter survival. 

We know that frogs from the same populations in the exact same locations can deposit eggs more than a month later or many weeks earlier than the average observed date of deposition, depending on the annual conditions (i.e., wetter or drier years). We suspect that the water temperature may be the most important driver in this plasticity, as it may act as a threshold which once exceeded, provides a very strong indicator of "summer" or future hydrologic condition.

However, the flow in a given reach of river can also be highly correlated with water temperature. Linkage between water temperature and patterns in flow may be tightly tied, particularly in rivers in the Sierra Nevada. Historically, Sierra Nevada river hydrology has been driven by a general Mediterranean pattern of wet (though variable) winter weather followed by spring snowmelt and warmer and drier summers. While temperature may exist as a spawning threshold, the actual initiation of breeding or spawning is highly variable in **R. boylii**, and likely requires additional enviromental cues such as changing water levels, flow magnitude, air temperature, humidity, etc.

These additional metrics may each act as environmental cues, but to conserve plasticity across environmental variablity present in a wide geographic range, it is unlikely that any of these can dictate oviposition independently (whereas a water temperature threshold may be a sole driver in some years). In order to determine the strongest predictor of breeding, we've collected oviposition data over 6 rivers in the Sierra Nevada from 2011 through 2016. In addition we collected a variety of metrics related to flow, air temperature, water temperature, water year index, day of water year, precipitation, and barometric pressure.

## Try Model, Model Fail

Let's try to assess whether water temperature, air temperature, flow (daily/weekly recession rates & discharge) play a role in predicting when breeding (oviposition occurs). To build this model we need to block by river, and by water year, as these are independent (though water year isn't *fixed*, it is fixed across all sites per each year).

First let's take a look at some test data. Using a subset (say just pull the **NF American**), can we build a model that gets at whether there is predictability in these variables despite shifts in timing and magnitude from year to year? Ideally this seems to be setup for a logistic regression, where 1 is the breeding initation or observation of eggs in the river, and 0 is all the days prior to that event. An *Event History Analysis* or *Survival Analysis* approach might work (see section on geometric distribution, Ch10, pg 328). 

### Get the Data & Tidy

```{r get and tidy data, eval=F, echo=F}

library(tidyverse)
library(lubridate)

load("data/master_dat_2011-2016.rda") 

# fill the REG col across all rows
#master_df$REG <- ifelse(master_df$site %in% c("MFA","MFY","RUB","SFY"), "R","U")

load("data/flow_dv_cfs_2011_6sites.rda") # updated and merged flows:

df <- master_df
# df <- master_df %>% filter(site!="MFY")
# df <- master_df %>% filter(month(date)>2 & month(date)<8 & !site=="MFA")
# df <- master_df %>% filter(month(date)>3 & month(date)<8 & site=="NFA" | site=="NFY")


# 2 NAs in dataset from 30 day avgs
df[!is.na(df$missData) & df$site=="RUB" & df$date==ymd("2011-05-26"),]$temp_30_max<-10.99
df[!is.na(df$missData) & df$site=="RUB" & df$date==ymd("2011-05-26"),]$temp_30_min<-9.7

rabo <- df[!is.na(df$missData),] %>% arrange(date)

# add unique rownames based on siteID
rabo <- rabo %>%
  mutate("siteID" = paste0(site, "-", row.names(.))) %>% 
  column_to_rownames(var = "siteID")  %>% as.data.frame
#names(rabo)
#rownames(rabo)

# create column with date for 15 and 30 day lags (for binomial logistic)
rabo_lag <- rabo %>% 
  mutate(d07 = date - 7, 
         d14 = date - 14,
         d21 = date - 21,
         d30 = date - 30) %>% 
  select(site, date, WY, d07:d30)

# rejoin / filter form orig dataset

rabo_bin7<- inner_join(df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d07")) %>% select(-c(date.y, d14:d30)) %>% mutate(lagEM="d07")
rabo_bin14 <- inner_join(df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d14")) %>% select(-c(date.y, d07:d30)) %>% mutate(lagEM="d14")
rabo_bin21 <- inner_join(df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d21")) %>% select(-c(date.y, d07:d30)) %>% mutate(lagEM="d21")
rabo_bin30 <- inner_join(df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d30")) %>% select(-c(date.y, d07:d21)) %>% mutate(lagEM="d30")

# bind up for one dataset of lags, add 1/0 col for breeding
rabo_LAGS<-rbind(rabo_bin7, rabo_bin14, rabo_bin21, rabo_bin30) %>% 
  mutate(breed = 0)
rm(list=ls(pattern = "rabo_bin*"))

# add breed col to orig dataset:
rabo <- rabo %>% mutate(breed = 1, lagEM="d00")

# make final logistic dataset, add 1/0 column
rabo_logist <- rbind(rabo_LAGS, rabo)

# fill the REG col across all rows
#rabo_logist$REG <- ifelse(rabo_logist$site %in% c("MFA","MFY","RUB","SFY"), "R","U")

#save(rabo_logist, file = "models/rabo_logistic_all_sites.rda")
```

Prepare data by removing much of the information that will be unused, and converting and scaling the data as needed.

```{r prepData, eval=T, echo=T}

library(tidyverse)
library(lubridate)
library(rethinking)

# custom scale function
cusScale <- function(x){
  (x - mean(x))/sd(x)
}

unScale <- function(x, y){
  (x * sd(y) + mean(y))
}

# LOAD DATA
load("models/rabo_logistic_all_sites.rda")

# UNREG: Filter down data, use only unreg sites
d1 <- dplyr::select(rabo_logist, site, breed, lagEM, DOWY, everything(), 
                    -date, -EM_per_km, -REG, -(obs_strt:apr_jul),
                    -len_km, -starts_with("CDEC"), -station, -DOY,
                    -WYsum, -lev_7_avg, -Q_cfs, -Q_min, -Q_7_cfs) %>% 
    #filter(!site=="MFA") %>% 
  filter(site=="NFY" | site=="NFA") %>%
  as.data.frame

# RM NAs, add id and site to rownames:
d1 <- d1 %>% filter(!is.na(temp_30_min))
#d1_rownames<- paste0(d1$site, "-",d1$WY, "-", seq(1:nrow(d1)))
d1$site <- as.factor(d1$site)
d1$lagEM <- as.factor(d1$lagEM)

# scale all data and rebind site and breed info:
d1s <- d1
d1s[,c(4:30)] <- apply(d1[,c(4:30)], 2, cusScale) # center and scale
d1s$site <- coerce_index(d1s$site) # for modeling
#d1s$WY <- coerce_index(d1s$WY) # for modeling
d1s$lagEM <- coerce_index(d1s$lagEM) # for modeling
#d1s <- d1s %>% rename(river=site, wyind=Index) # rename some vars

# update cols
d1$Qmx_log <- log(d1$Q_max)
d1$DOWY_log <- log(d1$DOWY)
d1s$DOWY <- d1$DOWY
d1$deltLevEX<-exp(d1$deltLev)
d1$lagEM<-coerce_index(d1$lagEM)
d1$obs <- 1:nrow(d1)
d1$river<-coerce_index(d1$site)

# only the breeding points?
d1 <- d1 %>% filter(breed==1)
d1s <- d1s %>% filter(breed==1)


# ALL DATA: Filter down data, use only reg sites
d2 <- dplyr::select(rabo_logist, site, breed, lagEM, DOWY, everything(), 
                    -date, -EM_per_km, -(obs_strt:apr_jul),
                    -len_km, -starts_with("CDEC"), -station, -DOY,
                    -WYsum, -lev_7_avg, -Q_cfs, -Q_min, -Q_7_cfs) %>% 
  filter(!site=="MFA", !site=="MFY") %>% #, !site=="NFY", !site=="NFA") %>%
  as.data.frame

# RM NAs, add id and site to rownames:
d2 <- d2 %>% filter(!is.na(temp_30_min)) #rm the NAs
d2$site <- factor(d2$site)
d2$REG_id <-ifelse(d2$REG=="R",1,0)
d2$lagEM <- as.factor(d2$lagEM)
d2 <- d2 %>% select(-REG)

# scale all data and rebind site and breed info:
d2s <- d2
d2s[,c(5:30)] <- apply(d2[,c(5:30)], 2, cusScale) # center and scale
d2s$site <- coerce_index(d2s$site) # for modeling
d2s$lagEM <- coerce_index(d2s$lagEM) # for modeling

# update cols
d2$Qmx_log <- log(d2$Q_max)
d2$DOWY_log <- log(d2$DOWY)
d2s$DOWY <- d2$DOWY
d2$deltLevEX<-exp(d2$deltLev)
d2$lagEM<-coerce_index(d2$lagEM)
d2$obs <- 1:nrow(d2)
d2$river<-coerce_index(d2$site)
d2s$WY_id <- coerce_index(d2$WY)

# only the breeding points?
d2 <- d2 %>% filter(breed==1)
d2s <- d2s %>% filter(breed==1)



dowy_labs<-c("Oct","Nov","Dec","Jan", "Feb","Mar", "Mar-15", "Apr-01", "Apr-15", "May-01", "May-15", "Jun-01", "Jun-15", "Jul-01", "Jul-15", "Aug", "Aug-15", "Sep")
dowy_breaks<-c(1, 32, 62, 93, 124, 152, 167, 183, 198, 213, 228, 244, 259, 274, 289, 305, 320, 336)
dowys<-data.frame("mon"=dowy_labs, "dowy"=dowy_breaks)

```

## Do Some Exploratory Modeling

After initially trying logistic regression, I think the better approach may be using a continuous variable (DOWY), and including breeding as a binary 1/0. It would allow a better sense of how relevant the effect is on breeding, alternatively I can model just the breeding points and see which are strongest predictors, then use only those variables for the mixed (0/1) dataset.

### Poisson Models

```{r Poisson1}
# dowy has to be positive
#d2s$WY_id <- coerce_index(d2$WY)
# breeding only
#d1 <- d1 %>% filter(breed==1)
#d1s <- d1s %>% filter(breed==1)

# Model 1: Varying Intercept for WY, breeding only, all sites
m1<- map2stan(
  alist(
    DOWY ~ dpois(mu),
    log(mu) <- a + a_wy[WY_id] + bt7mx*temp_7_max + bt30mn*temp_30_min + bQCV*Q_CV + bdLev*deltLev + bwyi*Index + bdQ*deltQ + bReg*REG_id,
    a ~ dnorm(0, 10),
    a_wy[WY_id] ~ dnorm(0, sigma_wy),
    c(bt7mx, bt30mn, bQCV, bdLev, bwyi, bdQ, bReg) ~ dnorm(0,10),
    sigma_wy ~ dexp(1)
),
data=d2s, iter=1e4, chains=4, cores=2)


# plots and stuff
plot(m1)
dev.off()
#pairs(m1)
precis(m1, depth=2, warn=F)
plot(precis(m1, pars = c("a_wy","bt7mx", "bt30mn", "blevCV", "bQCV", "bdLev", "bwyi", "bdQ",
                   "bReg","btCV", "sigma_wy"),  depth=2,warn=F))
```

So this means the model predicts a decrease in `DOWY` when `REG`==1, and an increase in `DOWY` with increasing `Water Index`. Interestingly, this model shows Rhats > 1, so something odd is going on here, and perhaps we should reduce the dnorm(mean back to 1 or 0). Here's the output from the **First Run** (`a ~ dnorm(0, 10)` and `a_site[site] ~ dnorm(a, sigma_site)`.


 > Changing the a ~ dnorm(0, 10) for the intercept made a big difference. Better Rhats and smaller SD across coefficients

 > Finally, changing the varying intercept to adapt not to the general intercept, but to 0 and the sigma_site appears to help.

``` 
           Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
a         5.44   0.04       5.39       5.49  7523    1
a_wy[1]   0.01   0.06      -0.06       0.09  6713    1
a_wy[2]  -0.02   0.04      -0.08       0.03  5813    1
a_wy[3]  -0.02   0.04      -0.07       0.04  6065    1
a_wy[4]   0.02   0.04      -0.04       0.08  6192    1
a_wy[5]   0.00   0.04      -0.06       0.06  7257    1
a_wy[6]   0.01   0.04      -0.04       0.07  7729    1
bt7mx     0.01   0.02      -0.02       0.05  7090    1
bt30mn   -0.01   0.02      -0.03       0.02  9525    1
bQCV      0.01   0.02      -0.02       0.05  8261    1
bdLev    -0.01   0.03      -0.05       0.04  6198    1
bwyi      0.06   0.03       0.02       0.10  6364    1
bdQ       0.01   0.02      -0.03       0.04  7078    1
bReg     -0.04   0.03      -0.10       0.01  7682    1
sigma_wy  0.04   0.04       0.00       0.09  1659    1
```


```{r Poisson2}

# Model 2: scaled

m2<- map2stan(
  alist(
    DOWY ~ dpois(mu),
    log(mu) <- a + a_site[site] + bt7mx*temp_7_max + bt30mn*temp_30_min + blevCV*lev_CV + bQCV*Q_CV + bdLev*deltLev + bwyi*Index + bReg*REG_id + bW7air*W_air_7_avg + bdppt*days_no_ppt,
    a ~ dnorm(0,10),
    a_site[site] ~ dnorm(0, sigma_site),
    c(bt7mx, bt30mn, blevCV, bQCV, bdLev, bwyi, bReg, bW7air, bdppt) ~ dnorm(0,10),
    sigma_site ~ dexp(1)
),
data=d2s, iter=1e4, chains=4, cores=2)



# plots and stuff
plot(m2)
dev.off()
precis(m2, depth=2, warn=F)
plot(precis(m2, depth=2,warn=F))

compare(m1, m2)
```

```{r poisson3}

# Model 3: scaled

m3<- map2stan(
  alist(
    DOWY ~ dpois(mu),
    log(mu) <- a + a_wy[WY_id] + bt7mx*temp_7_max + bt30mn*temp_30_min + blevCV*lev_CV + 
      bQCV*Q_CV + bdLev*deltLev + bwyi*Index + bdQ*deltQ + bReg*REG_id + btCV*temp_CV,
    a ~ dnorm(0, 10),
    a_wy[WY_id] ~ dnorm(0, sigma_wy),
    c(bt7mx, bt30mn, blevCV, bQCV, bdLev, bwyi, bdQ, bReg, btCV) ~ dnorm(0,10),
    sigma_wy ~ dexp(1)
),
data=d2s, iter=1e4, chains=4, cores=2)



# plots and stuff
plot(m3)
dev.off()
precis(m3, depth=2, warn=F)
plot(precis(m3, pars = c("a_wy","bt7mx", "bt30mn", "blevCV", "bQCV", "bdLev", "bwyi", "bdQ",
                   "bReg","btCV", "sigma_wy"), depth=2, warn=F))
abline(v=0, lty=2)

compare(m1, m3)

```



Looks like the model with `temp_7_max`, and `temp_30_mn` performed best, but not significantly so. The model with `ppt` and other temp values may be important. Ultimately we need to make some plots to figure this out. Also helps to create an ensemble model so that any one parameter gets "averaged" and avoids issues with trying lots of different models until you get one that "works".

I can't figure out how to extract predictions from my ensemble model for a given set of variables, or how to make a residual plot. 

### Regression

```{r gaussian1}

m4 <- map2stan(
  alist(
    DOWY ~ dnorm( mu , sigma),
    mu <- a + a_site[site] + bt7mx*temp_7_max + 
      bt30mn*temp_30_min + bQCV*Q_CV + bdLev*deltLev +  blevCV*lev_CV + bwyi*Index + 
      bdQ*deltQ + bReg*REG_id + btCV*temp_CV,
    a ~ dnorm(0 , 100 ) ,
    a_site[site] ~ dnorm(a, sigma_site),
    bt7mx ~ dnorm( 11 , 10 ) ,
    bt30mn ~ dnorm( 7 , 10 ) ,
    bQCV ~ dnorm(5, 10),
    bdLev ~ dnorm(1, 10),
    blevCV ~ dnorm(2,10),
    bwyi ~ dnorm(6, 10),
    c(bdQ, bReg) ~ dnorm(0, 10),
    btCV ~ dnorm(8, 10),
    sigma ~ dnorm(1, 10),
    sigma_site ~ dcauchy(0,1)
  ),
  data=d2, iter=8000 , chains=4, cores=2
)

plot(m4)
dev.off()
precis(m4, depth=2, warn=F)
plot(precis(m4, depth=1))

```

```{r gaussian2}

m5 <- map2stan(
  alist(
    DOWY ~ dnorm( mu , sigma),
    mu <- a + a_wy[WY_id] + bt7mx*temp_7_max + bt30mn*temp_30_min + blevCV*lev_CV + 
      bQCV*Q_CV + bdLev*deltLev + bwyi*Index + bdQ*deltQ + bReg*REG_id + btCV*temp_CV,
    a ~ dnorm(0, 10),
    a_wy[WY_id] ~ dnorm(0, sigma_wy),
    c(bt7mx, bt30mn, blevCV, bQCV, bdLev, bwyi, bdQ, bReg, btCV) ~ dnorm(0,10),
    sigma ~ dnorm(0,10),
    sigma_wy ~ dcauchy(0,1)
  ),
  data=d2s, iter=8000 , chains=4, cores=2
)

plot(m5)
dev.off()
precis(m5, depth=2, warn=F)
plot(precis(m5, depth=1))

compare(m1, m3, m5)

```
 So best model is Gaussian Model 5!
#### Plots

```{r plots_m5_t7max}

post4<-extract.samples(m5)

plot( DOWY ~ temp_7_max , data=d1, pch=ifelse(d1$lagEM==1, 16, 21), col=ifelse(d1$WY==2011, rangi2, "red"))

temp_7_max.seq <- seq( from=0 , to=18 , by=0.5)

# use link to compute mu for each sample from posterior
# and for each temp in temp.seq
mu <- link( m5, 
            data=data.frame(temp_7_max=temp_7_max.seq, 
                            temp_30_min=0, lev_CV=0, WY_id=3,
                            Q_CV=0, deltLev=0, Index=0,
                            deltQ=0, REG_id=0, temp_CV=0))

# use type="n" to hide raw data
plot( DOWY ~ temp_7_max , data=d1, pch=ifelse(d1$lagEM==1, 16, 21), col=ifelse(d1$WY==2011, rangi2, "red"), yaxt='n', ylab="", xlim=c(4,18))

# add axes
aty <- seq(213, 289, by = 15)
labelsY<-dowys$mon[10:15]
#axis(side=2, at = aty, las=1)
axis(side=2, at = aty, labels=labelsY, las=1)

# loop over samples and plot each mu value
# for ( i in 1:500 )
#     points( temp_7_max.seq , mu[i,] , pch=21 , col="gray", bg=col.alpha(rangi2,0.2) )

# summarize the distribution of mu
mu.mean <- apply( mu , 2 , mean )
mu.HPDI89 <- apply( mu , 2 , HPDI , prob=0.89 )
mu.HPDI97 <- apply( mu , 2 , HPDI , prob=0.97 )
mu.HPDI67 <- apply( mu , 2 , HPDI , prob=0.67 )

lines( temp_7_max.seq , mu.mean )
shade( mu.HPDI97 , temp_7_max.seq, col = col.alpha("purple", 0.1) )
shade( mu.HPDI89 , temp_7_max.seq) # plot a shaded region
shade( mu.HPDI67 , temp_7_max.seq)

#d1$WY <- d1$WY+2010 # switch years back to regular

# identify some points
identify( x=d1$temp_7_max , y=d1$DOWY , 
          labels=paste0(d1$site,"-",d1$WY), cex=0.8 )
```



```{r plots_m5_levDelt}
deltLev.seq <- seq( from=0.74 , to=1.2 , length.out = 40)

# use link to compute mu for each sample from posterior
# and for each temp in temp.seq
mu2 <- link( m5, 
            data=data.frame(temp_7_max=1, 
                            lagEM=1, temp_30_min=1,
                            Q_CV=1, 
                            deltLevEX=deltLev.seq, 
                            W_air_7_avg=1,
                            days_no_ppt=1, Index=10))
str(mu2)

# use type="n" to hide raw data
plot( DOWY ~ log(deltLevEX) , data=d1, pch=ifelse(d1$lagEM==1, 16, NA), col=ifelse(d1$WY==2011, rangi2, "red"))

# loop over samples and plot each mu value
# for ( i in 1:40 )
#     points( log(deltLev.seq) , mu2[i,] , pch=21 , col="gray", bg=col.alpha(rangi2,0.1) )

# summarize the distribution of mu
mu2.mean <- apply( mu2 , 2 , mean )
mu2.HPDI89 <- apply( mu2 , 2 , HPDI , prob=0.89 )
mu2.HPDI97 <- apply( mu2 , 2 , HPDI , prob=0.97 )
mu2.HPDI67 <- apply( mu2 , 2 , HPDI , prob=0.67 )

lines( log(deltLev.seq) , mu2.mean )
shade( mu2.HPDI97 , log(deltLev.seq), col = col.alpha("purple", 0.1) )
shade( mu2.HPDI89 , log(deltLev.seq)) 
shade( mu2.HPDI67 , log(deltLev.seq), col=col.alpha("red", 0.1))

# identify some points
identify( x=log(d1$deltLevEX) , y=d1$DOWY , 
          labels=paste0(d1$site,"-",d1$WY), cex=0.8 )

```

Maybe try an obs vs. modeled plot but use the regulated data...see how far off it is from the observed.




#### Notes from Myfanwy 2017-05-24

Use DOWY, not binomial, sites are coin flips. What triggers breeding, but doesn't help answer more important factors of what drives breeding? Want response to be as continuous as possible. 

**DOWY as response**
gammaPoisson, has individual "rate", rate should be affected in same way by different predictor variables. Different sites as nested variables, rate varies by site. 

**Survival Analysis**

How long does an event take to occur, (i.e., time to breeding)? Freezing over in a lake as example. Continuous segmented regression, (tobit regression) + probit model with time series with latent variable.

**MultiState Model**

predicting frequencies that will be occupied on radio, occupied vs. not.

Hidden Markov model, model conditions leading up to observable state (hidden state). Hidden markov poisson, describe variability that characterizes this latent state that you don't observe, but you know it drives the latent state.

Eric Van Cleaves (multistate modeler, spatial component)

Input matrix: 365 x 30 variables
Each row is day of year
Whether a breeding event occurred on that day as binomial




```{r gamPoisson}

d1f <- d1 %>% filter(breed==1) # NFY and NFA breeding only

#change delts to positive:
d1f$deltQexp <- exp(d1f$deltQ)
d1f$deltLevexp <- exp(d1f$deltLev)
d1f$log_DOWY <- log(d1f$DOWY)

m3 <- map2stan(
  alist(
    log_DOWY ~ dgampois(mu, scale),
    log(mu) <- a + bt7mx*temp_7_max + bwyi*Index + bdeltLev * deltLevexp +
      bWairmx*W_air_30_max + blevCV*lev_CV,
    a ~ dnorm(0, 10),
    c(bt7mx, bwyi, bdeltLev, bWairmx, blevCV) ~ dnorm(0,1),
    scale ~ dcauchy(0,1)
  ),
  data=d1f,
  constraints=list(scale="lower=0"),
  start=list(scale=1),
  warmup=1000, iter=8000, chains=2, cores=2)

precis(m3)
plot(m3)

postcheck(m3)
#blue points show the empirical proportion on each row of the data
#open circles are the posterior mean p, with 89% percentile interval
# + symbols mark the 89% interval of predicted counts for breeding. Lots of dispersion expected here.


post3 <- extract.samples(m3)
quantile( logistic(post3$a) , c(0.025,0.5,0.975) )

# draw posterior mean dgam distribution
curve( dgampois(x,mean(logistic(post3$a)),mean(post3$scale)) , from=0 , to=1 ,
    ylab="Density" , xlab="probability", ylim=c(0,3) , lwd=2 )
# draw 100 beta distributions sampled from posterior
for ( i in 1:100 ) {
    p <- logistic( post3$a[i] )
    scale <- post3$scale[i]
    curve( dgampois(x,p,scale) , add=TRUE , col=col.alpha("black",0.2) )
}


```





```{r}
# show density of log-odds
coef(m1)

# make some plots
plot(x=d1$DOWY, y=d1$temp_7_max, pch=ifelse(d1$lagEM==1, 16, 21), col=ifelse(d1$WY==1, rangi2, "red"))

abline(a=exp(coef(m1)["bt7mx"]), b=exp(coef(m1)["bQCV"]),
       col="black", lty=2)


# vars:
#a_lag[lagEM] + bt7mx*temp_7_max + bt30mn*temp_30_min + bQCV*Q_CV + bdLev*deltLevEX

# counterfactual
d.pred <- list(
    lagEM = rep(1,30),
    #DOWY = seq(150,300, length.out = 50),
    temp_7_max = seq(6,16, length.out = 30)
    #temp_30_min = seq(4,16, length.out = 30),
    #Q_CV = seq(0,40, length.out = 30),
    #deltLevEX = seq(0.7, 1.2, length.out = 30)
)

#a_lag_sims <- rnorm(20000,,post1$sigma_lag)
#a_lag_sims <- matrix(a_lag_sims,2000,10)
link.m1 <- link( m2 , n=2000 , data=d.pred)

# plot raw data
plot(d1$DOWY~d1$temp_7_max, pch=ifelse(d1$lagEM==1, 16, 21),
     col=ifelse(d1$WY==1, rangi2, "red"),
     #xlim=c(0,300), ylim=c(0,30),
     xlab="Temp 7 max" , ylab="DOWY")

# plot posterior median
mu.median <- apply( link.m1 , 2 , median )
lines(d.pred$temp_7_max, mu.median)

# plot 97%, 89%, and 67% intervals (all prime numbers)
mu.PI <- apply( link.m1 , 2 , PI , prob=0.97 )
shade(mu.PI, d.pred$temp_7_max )
mu.PI <- apply( link.m1 , 2 , PI , prob=0.89 )
shade(mu.PI, d.pred$temp_7_max )
mu.PI <- apply( link.m1 , 2 , PI , prob=0.67 )
shade(mu.PI, d.pred$temp_7_max )

```

```{r jacobgampoisson}

#########
# from Jacob 05/17/17
mz43 <- map2stan(
  alist(
    Zoops ~ dgampois(mu,scale),
    log(mu) <- a_site[site_id] + bt*temp + bno * NO3.N + bp * PO4.P + bd * DOC + bj * JulianDay,
    a_site[site_id] ~ dcauchy(10,sigma_site),
    sigma_site ~ dcauchy(1,1),
    c(bt,bno,bp,bd,bj) ~ dnorm(0,1),
    scale ~ dcauchy(0,2)
  ),
  data=zb,
  constraints=list(scale="lower=0"),
  start=list(scale=2)
)

```

