---
title: "Oviposition Logistic"
author: "Ryan Peek"
date: "Updated: `r format(Sys.Date())`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("../"))
```

## Try Model, Model Fail

Let's try to assess whether water temperature, air temperature, flow (daily/weekly recession rates & discharge) play a role in predicting when breeding (oviposition occurs). To build this model we need to block by river, and by water year, as these are independent (though water year isn't *fixed*, it is fixed across all sites per each year).

First let's take a look at some test data. Using a subset (say just pull the **NF American**), can we build a model that gets at whether there is predictability in these variables despite shifts in timing and magnitude from year to year?

### Get the Data & Tidy

```{r get and tidy data}
library(tidyverse)
library(lubridate)

load("data/master_dat_2011-2016.rda") 
load("data/flow_dv_cfs_2011_6sites.rda") # updated and merged flows:

df <- master_df
# df <- master_df %>% filter(site!="MFY")
# df <- master_df %>% filter(month(date)>2 & month(date)<8 & !site=="MFA")
# df <- master_df %>% filter(month(date)>3 & month(date)<8 & site=="NFA" | site=="NFY")


# 2 NAs in dataset from 30 day avgs
df[!is.na(df$missData) & df$site=="RUB" & df$date==ymd("2011-05-26"),]$temp_30_max<-10.99
df[!is.na(df$missData) & df$site=="RUB" & df$date==ymd("2011-05-26"),]$temp_30_min<-9.7

rabo <- df[!is.na(df$missData),] %>% arrange(date)

# add unique rownames based on siteID
rabo <- rabo %>%
  mutate("siteID" = paste0(site, "-", row.names(.))) %>% 
  column_to_rownames(var = "siteID")  %>% as.data.frame
#names(rabo)
#rownames(rabo)

# create column with date for 15 and 30 day lags (for binomial logistic)
rabo_lag <- rabo %>% 
  mutate(d7 = date - 7, 
         d14 = date - 14,
         d21 = date - 21,
         d30 = date - 30) %>% 
  select(site, date, WY, d7:d30)

# rejoin / filter form orig dataset

rabo_bin7<- inner_join(master_df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d7")) %>% select(-c(date.y, d14:d30)) %>% mutate(lagEM="d7")
rabo_bin14 <- inner_join(master_df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d14")) %>% select(-c(date.y, d7:d30)) %>% mutate(lagEM="d14")
rabo_bin21 <- inner_join(master_df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d21")) %>% select(-c(date.y, d7:d30)) %>% mutate(lagEM="d21")
rabo_bin30 <- inner_join(master_df, rabo_lag, by=c("site"="site", "WY"="WY", "date"="d30")) %>% select(-c(date.y, d7:d21)) %>% mutate(lagEM="d30")

# bind up for one dataset of lags, add 1/0 col for breeding
rabo_LAGS<-rbind(rabo_bin7, rabo_bin14, rabo_bin21, rabo_bin30) %>% 
  mutate(breed = 0)
rm(list=ls(pattern = "rabo_bin*"))

# add breed col to orig dataset:
rabo <- rabo %>% mutate(breed = 1, lagEM="d0")
# make final logistic dataset, add 1/0 column
rabo_logist <- rbind(rabo_LAGS, rabo)

#d <- rabo %>% dplyr::select(-(obs_strt:apr_jul), -len_km, -starts_with("CDEC"), -station, -WY, -DOY)
#names(d)

```


## Rethinking Model

```{r varying effects, eval=F, echo=T}
library(rethinking)

# Only UNREG
d.1 <- dplyr::select(rabo_logist, DOWY, everything(), -date, -EM_per_km, -REG,
                     -(obs_strt:apr_jul), -len_km, -starts_with("CDEC"), 
                     -station, -DOY, -WYsum, -lev_7_avg, -Q_cfs, 
                     -Q_min, -Q_7_cfs) %>% 
  filter(site=="NFY" | site=="NFA") %>% select(-lagEM) %>% 
  as.data.frame

# RM NAs, add id and site to rownames:
d.1 <- d.1 %>% filter(!is.na(temp_30_min))
d.1_rownames<- paste0(d.1$site, "-",d.1$WY, "-", seq(1:nrow(d.1)))
d.1 <- select(d.1, -site, -WY)

# an intercept only model of breeding
m10.1 <- map(
    alist(
        breed ~ dbinom( 1 , p ) ,
        logit(p) <- a ,
        a ~ dnorm(0,10)
),
    data=d.1 )

precis(m10.1)
logistic(c(-1.86, -1.34, -0.82)) # about a 20% chance of breeding based on these data

# scale the data
d.1s<-scale(d.1[,c(1:26)]) %>% as.data.frame() %>%  mutate(breed=d.1$breed)

# now add other stuff
m10.2 <- map(
    alist(
      breed ~ dbinom( 1 , p ) ,
      logit(p) <- a + bt7*temp_7_avg + bwyi*Index + 
        bdeltLev*deltLev + bQCV*Q_CV + bdeltQ*deltQ + 
        btCV*temp_CV + bppt*W_humidity_avg ,
      a ~ dnorm(0,5) ,
      c(bt7, bwyi, bdeltLev, bQCV, bdeltQ, 
        btCV, bppt) ~ dnorm(0,5)
      ),
    data=d.1s)

precis(m10.2)
logistic(c(1.63, 0.96,-.94, -1.01, 0.80)) # about a 20% chance of breeding based 

m10.2stan <- map2stan( m10.2 , data=d.1s , iter=1e4 , warmup=1000 )
precis(m10.2stan)
plot(m10.2stan)
plot(precis(m10.2stan))


# now add other stuff
m10.3 <- map(
    alist(
      breed ~ dbinom( 1 , p ) ,
      logit(p) <- a + bt7*temp_7_avg + bwyi*Index + 
        bdeltLev*deltLev + bQCV*Q_CV + bdeltQ*deltQ + 
        btCV*temp_CV + bppt*W_humidity_avg + bDOWY*DOWY,
      a ~ dnorm(0,5) ,
      c(bt7, bwyi, bdeltLev, bQCV, bdeltQ, 
        btCV, bppt, bDOWY) ~ dnorm(0,5)
      ),
    data=d.1s)

precis(m10.3)
plot(precis(m10.3))
compare(m10.2, m10.3)

exp(1.26)



#########
# from Jacob 05/17/17
mz43 <- map2stan(
  alist(
    DOWY ~ dgampois(mu,scale),
    log(mu) <- a_river[river_id] + bt7*temp_7_avg + bwyi*Index + bdeltLev * deltLev +
      bQCV * Q_CV + bdeltQ * deltQ + bQ*Q_cfs + bWair*W_air_30_max + btCV*temp_CV,
    a_river[river_id] ~ dcauchy(10,sigma_site),
    sigma_site ~ dcauchy(1,1),
    c(bt7, bwyi, bdeltLev, bQCV, bdelQ, bQ, bWair, btCV) ~ dnorm(0,1),
    scale ~ dcauchy(0,2)
  ),
  data=d,
  constraints=list(scale="lower=0"),
  start=list(scale=2)
)

```


## LASSO glm 

```{r lasso}

library(glmnet)

# Only UNREG
d.1 <- dplyr::select(rabo_logist, DOWY, everything(), -date, -EM_per_km, -REG,
                     -(obs_strt:apr_jul), -len_km, -starts_with("CDEC"), 
                     -station, -DOY, -WYsum, -lev_7_avg, -Q_cfs, 
                     -Q_min, -Q_7_cfs) %>% 
  filter(site=="NFY" | site=="NFA") %>% 
  as.data.frame

# RM NAs, add id and site to rownames:
d.1 <- d.1 %>% filter(!is.na(temp_30_min))
d.1_rownames<- paste0(d.1$site, "-",d.1$WY, "-", seq(1:nrow(d.1)))
d.1 <- select(d.1, -site, -WY)
d.1$breed <-as.factor(d.1$breed)
d.1$lagEM <- as.factor(d.1$lagEM)

# make the model matrix for binomial
x <- model.matrix(breed~., data=d.1)
x <- x[,-1] # remove the response var column

# model matrix for gaussian
xG<- d.1 %>% filter(lagEM=="d0") %>% select(-breed, -lagEM)
x2 <- model.matrix(DOWY~., data=xG)
x2 <- x2[,-1] # remove the response var column

# MODEL: BINOMIAL
fit = glmnet(x=x, y=d.1$breed, family = "binomial")
plot(fit, label=T)
print(fit)
coef(fit,s=0.05)

# MODEL: GAUSSIAN
fit2 = glmnet(x=x2, y=xG$DOWY)
plot(fit2, label=T)
print(fit2)
coef(fit2,s=0.05)

# create matrix for prediction (rows, cols)
nx = matrix(rnorm(nrow(x2)*ncol(x2)),nrow(x2),ncol(x2))
predict(fit2,newx=nx,s=c(0.1,0.05)) # new predictions

# cross validated vs. breed
cvfit <- cv.glmnet(x=x2, y=xG$DOWY)
plot(cvfit)
cvfit$lambda.min
coef(cvfit, s=0.05)
coef(cvfit, s="lambda.min")

```

lamda.min is the value of 位位 that gives minimum mean cross-validated error. The other 位位 saved is lambda.1se, which gives the most regularized model such that error is within one standard error of the minimum. To use that, we only need to replace lambda.min with lambda.1se above

```{r}

newMod <-predict(cvfit, newx = x2, s = "lambda.min") %>% data.frame()
colnames(newMod)<-"predictions"
newMod$siteID<- d.1_rownames[1:12]

ggplot(newMod) + geom_point(aes(x=siteID, y=predictions), pch=16) +
  coord_flip() + ylab("Prob of Breeding") + xlab("")

```


## Logistic `glm` Model

Now let's run a model. See [here](http://stats.idre.ucla.edu/r/dae/logit-regression/)

```{r model}

# Only UNREG
xG<- d.1 %>% filter(lagEM=="d0") %>% select(-breed, -lagEM)

# All sites
d.2 <- dplyr::select(rabo_logist, DOWY, everything(), -date, -Index, -WYsum,
                     -EM_per_km, -station, -(obs_strt:apr_jul), 
                     -len_km, -starts_with("CDEC"), -DOY, -WYsum,
                     -Q_min, -Q_7_cfs, -lev_7_avg) %>%
  as.data.frame

# fix index
#d.2$breed <-as.integer(as.factor(d.2$breed))
d.2$lagEM <- as.integer(as.factor(d.2$lagEM))
d.2$site <- as.integer(as.factor(d.2$site))
d.2$REG <- as.integer(as.factor(d.2$REG))

# scaled
d.2.s<-scale(d.2) %>% as.data.frame


# run a gaussian response model (unscaled)
mod.gauss <- glm(DOWY ~ deltQ + Q_CV + Q_7_CV +
                   W_air_7_avg + W_air_30_max + W_humidity_avg +
                   temp_7_avg + temp_7_max + temp_30_min + temp_30_max +
                   temp_CV + lev_CV + deltLev + Index +
                   days_no_ppt, data = xG, family = "gaussian")
summary(mod.gauss)
anova(mod.gauss)

# run a logistic binomial response model (unscaled)
mod.logit <- glm(breed ~ deltQ + Q_CV + Q_7_CV +
                 W_air_7_avg + W_air_30_max + W_humidity_avg +
                 temp_7_avg + temp_7_max + temp_30_min + temp_30_max +
                 temp_CV + lev_CV + deltLev +
                 days_no_ppt + site, data = d.2, family = "binomial")
summary(mod.logit)
anova(mod.logit)
```

So **Deviance residuals** are a measure of model fit, and `AIC = 178.8`. For every one unit change in **`temp_7_max`** there is a log-odds of oviposition timing (breeding) increase of 20.2224, whereas a change in the stage (`lev_CV`) yields a strong negative change in the log odds of oviposition by -2.09

You can calculate the confidence intervals using the `confint` function.

```{r}
confint(mod.logit)

```

```{r}
# simulate and predict

newdata1 <- d %>% select(DOWY, site, lev_avg:deltQ) %>% group_by(site,  DOY) #%>% 
  summarize(airmin.7 = mean(airmin.7),
            days_wo_ppt = mean(days_wo_ppt),
            level.avg = mean(level.avg),
            temp.min.7 = mean(temp.min.7),
            level.7dL = mean(level.7dL))

# predict
newdata1$rankP <- predict(mylogit, newdata = newdata1, type = "response")
newdata1
ggplot() + geom_point(data=newdata1, aes(x=DOY, y=rankP, color=as.factor(river_id), shape=as.factor(WY_id)), size=3)
```




## BRT

```{r brt}
library(gbm)
library(dismo)
library(ggplot2)
library(viridis)

set.seed(33)

# gbm First Model -----
d.1brt <- dplyr::select(rabo_logist, DOWY, everything(), 
                     -date, -EM_per_km, -REG,
                     -(obs_strt:apr_jul), -len_km,
                     -starts_with("CDEC"), 
                     #-starts_with("W_"), 
                     -station, -DOY, -WYsum, 
                     -lev_7_avg, -Q_cfs, 
                     -Q_min, -Q_max, -Q_7_cfs) %>% 
  filter(site=="NFY" | site=="NFA") %>% 
  filter(!is.na(temp_30_min)) %>% 
  dplyr::select(breed, everything(), -Index, -lev_avg, -DOWY) %>%
  as.data.frame()
d.1brt$site <- as.factor(d.1brt$site)
d.1brt$lagEM <- as.factor(d.1brt$site)

gbm3s <- gbm.step(data = d.1brt,
                     gbm.x = 2:26,    
                     gbm.y = 1,
                     family = "bernoulli",  
                     tree.complexity = 2,   
                     learning.rate = 0.001, 
                     bag.fraction = 0.75,   
                     n.folds = 5,      
                     plot.main=T,
                     verbose=T) 

paste0("mean estimated deviance from CV: ", round(gbm3s$cv.statistics$deviance.mean,3))
paste0("SE estimated deviance from CV: ", round(gbm3s$cv.statistics$deviance.se,3))

# gbm simplify barplot ----

par(mar=c(5,12,3,3))
barplot(rev(summary(gbm3s, plotit=FALSE)$rel.inf), 
        horiz = TRUE, col = viridis(length(gbm3s$var.names)), 
        names = rev(summary(gbm3s, plotit=FALSE)$var), 
        xlab = "Relative influence",
        las=1, 
        main="Relative Influence")

topVars<-summary(gbm3s, plot=F) %>% as.tibble %>% filter(rel.inf>4)
topVars


## Another BRT but simplified
names(d.1brt)
topVars$var <- factor(topVars$var)
d.1simp <- dplyr::select(d.1brt, breed, site, deltQ, W_air_30_max,
                         temp_30_min, temp_7_max, deltLev,
                         W_humidity_avg, lev_CV)

gbm3s <- gbm.step(data = d.1simp,
                     gbm.x = 2:9,    
                     gbm.y = 1,
                     family = "bernoulli",  
                     tree.complexity = 2,   
                     learning.rate = 0.001, 
                     bag.fraction = 0.75,   
                     n.folds = 5,      
                     plot.main=T,
                     verbose=T) 

paste0("mean estimated deviance from CV: ", round(gbm3s$cv.statistics$deviance.mean,3))
paste0("se estimated deviance from CV: ", round(gbm3s$cv.statistics$deviance.se,3))

# gbm simplify barplot ----

par(mar=c(5,12,3,3))
barplot(rev(summary(gbm3s, plotit=FALSE)$rel.inf), 
        horiz = TRUE, col = viridis(length(gbm3s$var.names)), 
        names = rev(summary(gbm3s, plotit=FALSE)$var), 
        xlab = "Relative influence",
        las=1, 
        main="Relative Influence")

summary(gbm3s, plot=F)
```

